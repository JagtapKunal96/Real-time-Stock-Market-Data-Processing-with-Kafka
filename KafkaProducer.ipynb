{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2f20d9-58ff-410d-8ec2-abaa14e01e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kafka import KafkaProducer\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08491ad5-db8d-4d45-8978-117a8ea570f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=[':9092'], #change ip here\n",
    "                         value_serializer=lambda x: \n",
    "                         dumps(x).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "246863a5-a5aa-4077-8465-a19f76089a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec67ca01-2a13-42dd-96d6-f7d3afbc146e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m dict_stock \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto_dict(orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m producer\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStockData\u001b[39m\u001b[38;5;124m\"\u001b[39m,value \u001b[38;5;241m=\u001b[39m dict_stock)\n\u001b[1;32m----> 4\u001b[0m \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    dict_stock = df.sample(1).to_dict(orient = \"records\")[0]\n",
    "    producer.send(\"StockData\",value = dict_stock)\n",
    "    sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce2930-c715-4eeb-be72-cd0ea84b0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code you provided is a Python snippet that creates an infinite loop (while True) to continuously sample a random row from a DataFrame df, convert it to a dictionary (dict_stock), and then use a KafkaProducer object to send the dictionary as a message to the Kafka topic 'demo_test' once every second. Let's break down the code:\n",
    "\n",
    "# 1.while True:: This creates an infinite loop that will keep running the indented code block indefinitely.\n",
    "# 2.dict_stock = df.sample(1).to_dict(orient=\"records\")[0]: \n",
    "# This line randomly samples one row from the DataFrame df using the sample() method. \n",
    "# It then converts the sampled row to a dictionary using to_dict(orient=\"records\").\n",
    "# Since the to_dict() method returns a list of dictionaries, [0] is used to get the first (and only) dictionary from the list and assign it to the variable dict_stock.\n",
    "# 3.producer.send('demo_test', value=dict_stock): This uses the KafkaProducer object (assuming it is named producer) to send the dict_stock dictionary  as a message to the Kafka topic 'demo_test'. The message value will be the content of the dict_stock dictionary.\n",
    "# 4.sleep(1): This pauses the loop execution for 1 second using the sleep() function from the time module. This causes the loop to wait for 1 second before sampling the next row from the DataFrame and sending it as a new message to the Kafka topic.\n",
    "\n",
    "# In summary, the code creates a data stream by continuously sampling random rows from the DataFrame df, converting each sampled row to a dictionary, and sending it as a message to the Kafka topic 'demo_test'. The loop will run indefinitely, generating a new message and sending it every second until manually interrupted or stopped. This behavior is often seen in real-time data streaming applications where data is continuously ingested into Kafka for further processing or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43e6d31a-1da1-48cd-9d4b-c9ed2cfe78b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.flush() #clear data from kafka server"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
